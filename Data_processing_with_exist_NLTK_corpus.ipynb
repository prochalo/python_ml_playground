{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data processing with exist NLTK corpus.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxb0/jRxC6kjlYjvqNnMAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/provincit/python_ml_playground/blob/master/Data_processing_with_exist_NLTK_corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBZyDsh4Lbp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1f36d46e-8d97-448e-d668-b020438bb7b3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('names')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from nltk.corpus import names\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPtOQNXPORd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1f00c508-70b8-4565-91db-b80c86e791a2"
      },
      "source": [
        "print(\"\\nNumber of male names:\")\n",
        "print (len(names.words('male.txt')))\n",
        "print(\"\\nNumber of female names:\")\n",
        "print (len(names.words('female.txt')))\n",
        "male_names = names.words('male.txt')\n",
        "female_names = names.words('female.txt')\n",
        "print(\"\\nFirst 10 male names:\")\n",
        "print (male_names[0:15])\n",
        "print(\"\\nFirst 10 female names:\")\n",
        "print (female_names[0:15])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of male names:\n",
            "2943\n",
            "\n",
            "Number of female names:\n",
            "5001\n",
            "\n",
            "First 10 male names:\n",
            "['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim', 'Abdullah', 'Abe', 'Abel', 'Abelard', 'Abner']\n",
            "\n",
            "First 10 female names:\n",
            "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale', 'Abra', 'Acacia', 'Ada', 'Adah', 'Adaline']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXaMmwhqMZlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def letters_only(astr):\n",
        "  return astr.isalpha()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQOJlQYoMZpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(stop_words = \"english\", max_features=500)\n",
        "groups = fetch_20newsgroups()\n",
        "cleaned = []\n",
        "all_names = set(names.words())\n",
        "lemmitizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgyzp3FTNScr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for post in groups.data:\n",
        "  cleaned.append(' '.join([lemmitizer.lemmatize(word.lower()) \n",
        "  for word in post.split() \n",
        "  if letters_only(word) \n",
        "  and word not in all_names]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwR2jaREZSrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6403e1e3-4874-43aa-88b3-a37df69db5b4"
      },
      "source": [
        "transformed = cv.fit_transform(cleaned)\n",
        "print(cv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['able', 'accept', 'access', 'according', 'act', 'action', 'actually', 'add', 'address', 'ago', 'agree', 'algorithm', 'allow', 'american', 'anonymous', 'answer', 'anybody', 'apple', 'application', 'apr', 'arab', 'area', 'argument', 'armenian', 'article', 'ask', 'asked', 'assume', 'atheist', 'attack', 'attempt', 'available', 'away', 'bad', 'based', 'basic', 'belief', 'believe', 'best', 'better', 'bible', 'big', 'bike', 'bit', 'black', 'board', 'body', 'book', 'box', 'build', 'bus', 'business', 'buy', 'ca', 'california', 'called', 'came', 'car', 'card', 'care', 'carry', 'case', 'cause', 'center', 'certain', 'certainly', 'chance', 'change', 'check', 'child', 'chip', 'christian', 'church', 'city', 'claim', 'clear', 'clipper', 'code', 'college', 'color', 'come', 'coming', 'command', 'comment', 'common', 'communication', 'company', 'computer', 'computing', 'consider', 'considered', 'contact', 'control', 'controller', 'copy', 'correct', 'cost', 'country', 'couple', 'course', 'cover', 'create', 'crime', 'current', 'cut', 'data', 'day', 'db', 'deal', 'death', 'department', 'design', 'device', 'did', 'difference', 'different', 'discussion', 'disk', 'display', 'division', 'dod', 'doe', 'doing', 'drive', 'driver', 'drug', 'early', 'earth', 'easy', 'effect', 'email', 'encryption', 'end', 'engineering', 'entry', 'error', 'especially', 'event', 'evidence', 'exactly', 'example', 'expect', 'experience', 'explain', 'face', 'fact', 'faq', 'far', 'fast', 'federal', 'feel', 'figure', 'file', 'final', 'following', 'food', 'force', 'form', 'free', 'friend', 'ftp', 'function', 'game', 'general', 'getting', 'given', 'gmt', 'goal', 'god', 'going', 'good', 'got', 'government', 'graphic', 'great', 'greek', 'ground', 'group', 'guess', 'gun', 'guy', 'ha', 'hand', 'hard', 'hardware', 'having', 'head', 'health', 'hear', 'heard', 'hell', 'help', 'high', 'history', 'hit', 'hockey', 'hold', 'home', 'hope', 'house', 'human', 'ibm', 'idea', 'image', 'important', 'include', 'includes', 'including', 'individual', 'info', 'information', 'instead', 'institute', 'interested', 'interesting', 'international', 'internet', 'israeli', 'issue', 'jew', 'jewish', 'job', 'just', 'key', 'kill', 'killed', 'kind', 'know', 'known', 'la', 'large', 'later', 'law', 'le', 'lead', 'league', 'left', 'let', 'level', 'life', 'light', 'like', 'likely', 'line', 'list', 'little', 'live', 'local', 'long', 'longer', 'look', 'looking', 'lost', 'lot', 'love', 'low', 'machine', 'mail', 'main', 'major', 'make', 'making', 'man', 'manager', 'matter', 'maybe', 'mean', 'medical', 'member', 'memory', 'men', 'message', 'method', 'military', 'million', 'mind', 'mode', 'model', 'money', 'monitor', 'month', 'moral', 'mouse', 'muslim', 'na', 'nasa', 'national', 'near', 'need', 'needed', 'network', 'new', 'news', 'nice', 'north', 'note', 'number', 'offer', 'office', 'old', 'open', 'opinion', 'order', 'original', 'output', 'package', 'particular', 'past', 'pay', 'pc', 'people', 'period', 'person', 'personal', 'phone', 'place', 'play', 'player', 'point', 'police', 'policy', 'political', 'position', 'possible', 'post', 'posted', 'posting', 'power', 'president', 'press', 'pretty', 'previous', 'price', 'private', 'probably', 'problem', 'product', 'program', 'project', 'provide', 'public', 'purpose', 'question', 'quite', 'radio', 'rate', 'read', 'reading', 'real', 'really', 'reason', 'recently', 'reference', 'religion', 'religious', 'remember', 'reply', 'report', 'research', 'response', 'rest', 'result', 'return', 'right', 'road', 'rule', 'run', 'running', 'russian', 'said', 'sale', 'san', 'save', 'saw', 'say', 'saying', 'school', 'science', 'screen', 'scsi', 'second', 'section', 'security', 'seen', 'sell', 'send', 'sense', 'sent', 'serial', 'server', 'service', 'set', 'shall', 'short', 'shot', 'similar', 'simple', 'simply', 'single', 'site', 'situation', 'size', 'small', 'software', 'sort', 'sound', 'source', 'space', 'special', 'specific', 'speed', 'standard', 'start', 'started', 'state', 'statement', 'stop', 'strong', 'study', 'stuff', 'subject', 'sun', 'support', 'sure', 'taken', 'taking', 'talk', 'talking', 'tape', 'tax', 'team', 'technical', 'technology', 'tell', 'term', 'test', 'texas', 'text', 'thanks', 'thing', 'think', 'thinking', 'thought', 'time', 'tin', 'today', 'told', 'took', 'total', 'tried', 'true', 'truth', 'try', 'trying', 'turkish', 'turn', 'type', 'understand', 'unit', 'united', 'university', 'unix', 'unless', 'usa', 'use', 'used', 'user', 'using', 'usually', 'value', 'various', 'version', 'video', 'view', 'wa', 'want', 'wanted', 'war', 'water', 'way', 'weapon', 'week', 'went', 'western', 'white', 'widget', 'willing', 'win', 'window', 'woman', 'word', 'work', 'working', 'world', 'write', 'written', 'wrong', 'year', 'york', 'young']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f9widCrZeq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}